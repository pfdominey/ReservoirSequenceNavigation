{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IMPORTS AND FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Numpy backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "from numpy.linalg import norm\n",
    "from itertools import combinations\n",
    "\n",
    "from plotter import *\n",
    "from plotnine import *\n",
    "from easyesn.optimizers import GradientOptimizer\n",
    "from easyesn import PredictionESN\n",
    "from easyesn import BaseESN\n",
    "# note: you must make this change in the easyesn code\n",
    "# https://github.com/kalekiu/easyesn/issues/12\n",
    "from easyesn.optimizers import GridSearchOptimizer\n",
    "from easyesn import helper as hlp\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\"\"\" NOTES:\n",
    "    This file provides mechanisms to:\n",
    "    A) Data Processing\n",
    "        1) Load trajectories from csv files ( file must contain columns 'x', 'y')\n",
    "        2) Create a trajectory from a trajectory generator (see more documentation in respective function)\n",
    "        3) Load a generator from a csv file\n",
    "        4) Load a set of feeders from a csv file\n",
    "        5) Generate a matrix of place cell activations (row=place cell, column=time_index) \n",
    "           pc activation computed according to following formula:\n",
    "                 e^( log(K) * ||pos - pc_center||^2 / r^2  )\n",
    "           where \n",
    "                r is the place cell's radius\n",
    "                K is the place cell's activation value at the radius\n",
    "    \n",
    "    B) Plot data\n",
    "        Imports functionalities from 'plotter.py' which uses library matplotlib\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# CONSTANTS\n",
    "PC_VALUE_AT_RADIUS = 0.8  # 0.2 activation value (constant K in pc activation formula)\n",
    "\n",
    "\n",
    "def list_files(folder, extension=\"\"):\n",
    "    \"\"\" lost all files in the folder with the given extension\n",
    "    \"\"\"\n",
    "    return sorted([ f for f in os.listdir(folder) if f.endswith(extension)])\n",
    "\n",
    "def pad_single_sequence(s, length):\n",
    "    \"\"\" Pads a dataframe so that it has the given length.\n",
    "        we expect len(s) < length, if so, the first element is repeated as necessary.\n",
    "    \"\"\"\n",
    "    pad_vectors = [ s.loc[[0]] ] * (length - len(s))\n",
    "    return pd.concat([* pad_vectors , s]).reset_index(drop=True)\n",
    "\n",
    "def pad_all_sequences(sequences):\n",
    "    \"\"\"\n",
    "        Pads all sequences so that they have the same number of elements.\n",
    "        Padding is added by repeating the first element as necessary\n",
    "    \"\"\"\n",
    "    longest = max([ len(s) for s in sequences.values() ])\n",
    "    return { k : pad_single_sequence(s, longest) for k, s in sequences.items() }\n",
    "\n",
    "def calculate_sequence_mean_displacement(sequence):\n",
    "    \"\"\"\n",
    "        Calculates the mean distance between consecutive points in the sequence.\n",
    "    \"\"\"\n",
    "    num_data = len(sequence)\n",
    "    displacements = sequence.loc[0:(num_data-2)].reset_index(drop=True) - sequence.loc[1:(num_data-1)].reset_index(drop=True)    \n",
    "    return norm(displacements, axis=1).mean()\n",
    "\n",
    "def load_path(file_name):\n",
    "    \"\"\"\" load csv fle specifying a path\n",
    "         file must contain at least columns 'x' and 'y'\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_name, delim_whitespace=True)\n",
    "    # return sequence[['x', 'y']].to_numpy()\n",
    "\n",
    "\n",
    "def load_generator(file_name):\n",
    "    \"\"\"\" load csv fle specifying a path generator\n",
    "             file must contain at least columns 'x', 'y' and 'steps'\n",
    "        \"\"\"\n",
    "    return pd.read_csv(file_name, delim_whitespace=True)\n",
    "\n",
    "\n",
    "def generate_path(generator):\n",
    "    \"\"\" Generate a path using a generator\n",
    "        'generator' is a pandas data frame containing at least 3 columns 'x' 'y' and 'steps'\n",
    "        Column 'steps' indicate the number of step to reach the following way point (the\n",
    "        value in the last row is ignored since it is the last point in the path)\n",
    "    \"\"\"\n",
    "\n",
    "    # convert data to numpy arrays\n",
    "    xy = generator[['x', 'y']].to_numpy()  # waypoints\n",
    "    steps = generator['steps'].to_numpy()  #\n",
    "\n",
    "    # interpolate each segment\n",
    "    # endpoint=False will avoid repeating the last coordinate of each segment\n",
    "    interpolator = lambda m_tuple: np.linspace(*m_tuple, endpoint=False)\n",
    "    data = zip(xy[:-1], xy[1:], steps[:-1])\n",
    "    path = np.concatenate(list(map(interpolator, data)) + [[xy[-1]]])\n",
    "    return pd.DataFrame(path, columns=['x', 'y'])\n",
    "\n",
    "\n",
    "def load_feeders(file_name):\n",
    "    \"\"\"\"Function to load a set of feeders\"\"\"\n",
    "    return pd.read_csv(file_name, delim_whitespace=True)[['x', 'y']]\n",
    "\n",
    "\n",
    "def load_place_cells(file_name):\n",
    "    \"\"\"\" Load csv fle specifying a set of place cells\n",
    "         file must contain at least columns 'x', 'y' and 'placeradius'\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_name, delim_whitespace=True)\n",
    "    # return pcs[['x', 'y']].to_numpy(), pcs['placeradius'].to_numpy()\n",
    "\n",
    "\n",
    "def calc_activation_matrix(path, pcs):\n",
    "    \"\"\" Calculate a matrix containing the activation of all place cells for all times.\n",
    "        Each row represents a place cell, while columns represent the time index.\n",
    "        Both 'pos' and 'pcs' are data frames containing the path and the set of place cells.\n",
    "    \"\"\"\n",
    "    # get number of pcs and position in path\n",
    "    num_pcs = len(pcs)\n",
    "    num_pos = len(path)\n",
    "\n",
    "    # convert data to numpy to operate\n",
    "    radii = pcs['placeradius'].to_numpy()\n",
    "    pcs = pcs[['x', 'y']].to_numpy()\n",
    "    pos = path[['x', 'y']].to_numpy()\n",
    "\n",
    "    # replicate the position vector by the number of place cells for easy operations\n",
    "    pos_tile = pos.reshape(1, -1, 2)\n",
    "    pos_all = np.tile(pos_tile, (num_pcs, 1, 1))\n",
    "\n",
    "    # replicate the place cells and radii by the number of positions for easy operations\n",
    "    pcs_tile = pcs.reshape(-1, 1, 2)\n",
    "    pcs_all = np.tile(pcs_tile, (1, num_pos, 1))\n",
    "    radii_all = np.tile(radii.reshape((-1, 1)), (1, num_pos))\n",
    "\n",
    "    # calculate the activations (see description of formula at the top of this file)\n",
    "    delta = pos_all - pcs_all\n",
    "    delta2 = (delta * delta).sum(2)\n",
    "    r2 = radii_all * radii_all\n",
    "    exponents = np.log(PC_VALUE_AT_RADIUS) * delta2 / r2\n",
    "    activations = np.exp(exponents)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def plot_paths_and_activations(pcs, sequence, activations, save_name, compare_sequence = None, title='', output_folder=''):\n",
    "    \"\"\"\n",
    "        Creates figures with two subplots.\n",
    "        Left plot shows heatmap representing the activation of the sequence vs time.\n",
    "        Right plot shows the place cells in space, and the sequence path.\n",
    "        If a compare sequence is given, the right plot also includes a second sequence to compare to\n",
    "    \"\"\"\n",
    "    # create ouput folder if it doesnt exist:\n",
    "    make_dirs(output_folder)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2 )\n",
    "    fig.suptitle(title)\n",
    "    f1 = axs[0]\n",
    "    f2 = axs[1]\n",
    "    f2.autoscale(enable=True)\n",
    "    f2.set_aspect('equal')\n",
    "    plot_activation_matrix_heatmap(activations, plot=f1)\n",
    "\n",
    "    plot_place_cells(pcs, plot=f2)  # add place cells to figure\n",
    "#    plot_maze(plot=f2)\n",
    "    if compare_sequence is not None:\n",
    "        plot_path(compare_sequence, plot=f2)\n",
    "    plot_path(sequence, plot=f2)\n",
    "#    plot_feeders(feeders, plot=f2, s=80, zorder=2)  # zorder can be used to move the layer up or down\n",
    "    plt.savefig(output_folder + save_name, dpi = 1200)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    \"\"\"\n",
    "        Returns the cosine similitude between two vectors\n",
    "    \"\"\"\n",
    "    return np.dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "\n",
    "def create_and_train_reservoir(activations):\n",
    "    \"\"\"\n",
    "        Creates and trains the reservoir network.\n",
    "        Activation sequences is used as input and expected output of the network.\n",
    "        Rows are expected to be place cells, while columns are expected to represent time indeces\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize random seed, and set reservoir dimensions\n",
    "    np.random.seed(1)\n",
    "    vectorDim = len(activations) # reservoir input dimension\n",
    "    numNode = 400   # number of reservoir nodes\n",
    "\n",
    "    # create training input and output sets, augment it 2^10 times: \n",
    "    inputDataTraining = activations.T \n",
    "    outputDataTraining = activations.T\n",
    "    print('activation shape:', activations.shape) \n",
    "    print('input data shape:', inputDataTraining.shape)\n",
    "\n",
    "    # augment data by concatenating 2^10 times\n",
    "    inputDataTraining = np.concatenate( [ inputDataTraining ] * 1024, axis = 0 )\n",
    "    outputDataTraining=inputDataTraining\n",
    "    print('augmented data shape:', inputDataTraining.shape)\n",
    "\n",
    "    # create and train network: \n",
    "    esn = PredictionESN(n_input=vectorDim, n_output=vectorDim, n_reservoir=numNode, leakingRate=0.05, regressionParameters=[1e-2], solver=\"lsqr\", feedback=False)\n",
    "    esn.fit(inputDataTraining, outputDataTraining, transientTime=\"Auto\", verbose=1)\n",
    "    return esn\n",
    "\n",
    "def predict_reservoir(trained_reservoir, activations, continuation=False):\n",
    "    \"\"\"\n",
    "        Uses the trained reservoir to predict using the activations as input\n",
    "        Activations should be a matrix with rows indicating pcs and columns indicating time\n",
    "        Resturns only the last few states\n",
    "    \"\"\"\n",
    "    prediction, reservoirStatesBuffer = trained_reservoir.predict(activations.T, continuation=continuation)\n",
    "    # print(reservoirStatesBuffer.shape)\n",
    "    return prediction, reservoirStatesBuffer[257:,:].T\n",
    "\n",
    "def plot_can_reservoir_distinguish_sequences( activations, states, integrators, input_similitudes, state_similitudes, integrator_similitudes, s1, s2, output_folder=''):\n",
    "    \"\"\"\n",
    "        Generates a plot with 6 subplots\n",
    "    \"\"\"\n",
    "    \n",
    "    fig= plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(f'Sequences: {s1} VS {s2}')\n",
    "    #fig.suptitle('State Trajectories', fontsize=16)\n",
    "    #fig.suptitle('State Trajectories')\n",
    "\n",
    "    plt.subplot(331)\n",
    "    plt.title('Input Temporal Structure 1')\n",
    "    #plt.plot( inputDataTesting[:76,:])\n",
    "    #sns.heatmap(activations, cmap=\"seismic\")\n",
    "    sns.heatmap(activations[s1])\n",
    "    #plt.ylim([-1.1,1])\n",
    "    \n",
    "    plt.subplot(334)\n",
    "    plt.title('Input Temporal Structure 2')\n",
    "    #plt.plot( inputDataTesting2[:76,:])\n",
    "    #sns.heatmap(activations2, vmin=0.4, vmax=1)\n",
    "    sns.heatmap(activations[s2])\n",
    "    #plt.ylim([-1.1,1])\n",
    "   \n",
    "\n",
    "\n",
    "    plt.subplot(337)\n",
    "    plt.title('Inputs Cosine Similarity')\n",
    "    plt.plot( input_similitudes[s1][s2])\n",
    "    plt.ylim([0,1.1])\n",
    "\n",
    "    plt.subplot(338)\n",
    "    plt.title('Reservoir States Cosine Similarity')\n",
    "    plt.plot( state_similitudes[s1][s2])\n",
    "    plt.ylim([0,1.1])\n",
    "    \n",
    "    plt.subplot(339)\n",
    "    plt.title('Integrator States Cosine Similarity')\n",
    "    plt.plot( integrator_similitudes[s1][s2])\n",
    "    plt.ylim([0,1.1])\n",
    "\n",
    "\n",
    "    # Following we plot the reservoir temporal structure, we can simplify printing only the first 10 states\n",
    "    resn = 10\n",
    "    plt.subplot(332)\n",
    "    plt.title('Reservoir States Temporal Structure 1')\n",
    "    plt.plot( states[s1][s1][:,:resn])\n",
    "    #plt.plot( inputDataTestingA[:,:5])\n",
    "    plt.ylim([-1.1,1])\n",
    "    \n",
    "    plt.subplot(335)\n",
    "    plt.title('Reservoir States Temporal Structure 2')\n",
    "    plt.plot( states[s1][s2][:,:resn])\n",
    "    #plt.plot( inputDataTestingB[:,:5])\n",
    "    plt.ylim([-1.1,1])\n",
    "    \n",
    "    \n",
    "    resn = 256\n",
    "    plt.subplot(333)\n",
    "    plt.title('Integrator States Temporal Structure 1')\n",
    "    plt.plot( integrators[s1][:,:resn])\n",
    "    #plt.plot( inputDataTestingA[:,:5])\n",
    "    # plt.ylim([-1.1,1])\n",
    "    \n",
    "    plt.subplot(336)\n",
    "    plt.title('Integrator States Temporal Structure 2')\n",
    "    plt.plot( integrators[s2][:,:resn])\n",
    "    #plt.plot( inputDataTestingB[:,:5])\n",
    "    # plt.ylim([-1.1,1])\n",
    "    \n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(output_folder + f'reservoirstates-Y-simplified_{s1}_{s2}.png')\n",
    "    return fig\n",
    "     \n",
    "\n",
    "def make_dirs(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        \n",
    "def create_empty_tabs(names):\n",
    "    %matplotlib inline\n",
    "    tabs = { n : widgets.Output() for n in names}\n",
    "    tab_widget = widgets.Tab(children = list(tabs.values()))\n",
    "    names = list(tabs.keys())\n",
    "    for i in range(len(names)):\n",
    "        tab_widget.set_title(i, names[i])\n",
    "    display(tab_widget)\n",
    "    return tabs\n",
    "        \n",
    "def create_or_add_to_tab_display(data, tab_widget=None):\n",
    "    %matplotlib inline\n",
    "    # get data to be displayed\n",
    "    tab_names = list(data)\n",
    "    tab_data = list(data.values())\n",
    "\n",
    "    # if tab widget not yet created, create it:\n",
    "    if tab_widget is None:\n",
    "        tab_widget = widgets.Tab(children = [ widgets.Output() for t in tab_names ])\n",
    "        for i in range(len(tab_names)):\n",
    "            tab_widget.set_title(i, tab_names[i])\n",
    "    \n",
    "    for i in range(len(tab_names)):\n",
    "        with tab_widget.children[i]:\n",
    "            display(tab_data[i])\n",
    "            \n",
    "    return tab_widget       \n",
    "        \n",
    "def linear_integrator_states(data, past_coef, present_coef):\n",
    "    result = np.zeros(data.shape)\n",
    "    result[0] = data[0]\n",
    "    for i in range(1,len(data)):\n",
    "        result[i] = result[i-1]*past_coef + data[i]*present_coef\n",
    "    return result\n",
    "\n",
    "def constant_map(groups, value):\n",
    "    return {g:value for g in groups}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PREPROCESS ROBOT SEQUENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INVERT AND STORE INVERTED ROBOT SEQUENCES\n",
    "input_folder  = 'input/robot_recordings/' \n",
    "output_folder = 'input/robot_recordings/inverted/'\n",
    "make_dirs(output_folder)\n",
    "files = list_files(input_folder, '.csv')\n",
    "\n",
    "def read_invert_save(input_folder, output_folder, file):\n",
    "    data = pd.read_csv(input_folder + f)\n",
    "    data2 = data.reindex(index=data.index[::-1]).reset_index(drop=True)\n",
    "    data2.to_csv(output_folder + f, index=False)\n",
    "    \n",
    "for f in files:\n",
    "    read_invert_save(input_folder, output_folder, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LOAD SEQUENCES AND CALCULATE ACTIVATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Average distance between samples in robot paths:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'fss_0': 0.10172203909764774,\n",
       " 'fss_1': 0.10024876655448742,\n",
       " 'kkk_0': 0.1037335119470402,\n",
       " 'kkk_1': 0.10272399158152683,\n",
       " 'sfs_0': 0.10098300073848074,\n",
       " 'sfs_1': 0.10472721395373853}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Paths and activations (may take some time)..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27813916986745449b908d13fecd71f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOLDERS \n",
    "folder_generators = 'input/'                           # folder where synthetic trajectory generators are stored\n",
    "folder_recordings = 'input/robot_recordings/'          # folder where robot paths are stored\n",
    "folder_inverted   = 'input/robot_recordings/inverted/' # folder where inverted robot paths are stored\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "paths = {} # dictionary of data frames representing paths\n",
    "activations = {} # history of place cell activations for each path in 'paths'\n",
    "\n",
    "# SYNTHETIC PATH GENERATOR FILES\n",
    "y_a = 'path-y-a'\n",
    "y_b = 'path-y-b'\n",
    "syn_fss = 'syn-fss'\n",
    "syn_sfs = 'syn-sfs'\n",
    "syn_mmm = 'syn-mmm'\n",
    "\n",
    "# LOAD PLACE CELLS AND FEEDERS\n",
    "pcs = load_place_cells('input/placecells.csv')\n",
    "abcde = load_path('input/abcde.csv')\n",
    "feeders = load_feeders('input/feeders.csv')\n",
    "\n",
    "\n",
    "# LOAD AND GENERATE SYNTHETIC PATHS\n",
    "synthetic_set1 = [ y_a, y_b ]\n",
    "synthetic_set2 = [ syn_fss, syn_sfs, syn_mmm ]\n",
    "paths.update({ f : generate_path(load_generator(folder_generators + f)) for f in synthetic_set1 + synthetic_set2 })\n",
    "\n",
    "\n",
    "# LOAD ROBOT PATHS\n",
    "paths_robot = { f[-9:-4] : pd.read_csv(folder_recordings + f)[['x','y']].copy()  for f in list_files(folder_recordings, '.csv') }\n",
    "paths_robot_inverted = { f'{f[-9:-4]}_inverted' : pd.read_csv(folder_inverted + f)[['x','y']].copy()  for f in list_files(folder_inverted, '.csv') }\n",
    "padded = pad_all_sequences(paths_robot)\n",
    "padded_inverted = pad_all_sequences(paths_robot_inverted)\n",
    "paths.update( padded )\n",
    "paths.update( padded_inverted  )\n",
    "\n",
    "\n",
    "# CALCULATE AND PRINT MEAN DISTANCE BETWEEN SAMPLES IN ROBOT PATHS\n",
    "robot_mean_distances = { k : calculate_sequence_mean_displacement(s) for k, s in paths_robot.items()} # need to use unpadded sequences, else averages extra zeros\n",
    "display(Markdown('## Average distance between samples in robot paths:'))\n",
    "display(robot_mean_distances)\n",
    "\n",
    "# CALCULATE PC ACTIVATIONS FOR EACH PATH\n",
    "activations.update({ k : calc_activation_matrix(p, pcs) for k, p in paths.items() })\n",
    "\n",
    "# PLOT PATHS AND ACTIVATIONS\n",
    "display(Markdown('## Paths and activations (may take some time)...'))\n",
    "save_folder = 'images/path_and_activations/'\n",
    "figures_PA =  { k:plot_paths_and_activations(pcs, p, activations[k], f'path_and_activation_{k}.png', title = f'Sequence {k}', output_folder = save_folder) \n",
    "                for k, p in paths.items() }\n",
    "\n",
    "tab_widget = create_or_add_to_tab_display(figures_PA) # {y_a:f1, y_b:f2})\n",
    "\n",
    "display(tab_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT INTERACTIVE PATH POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"4147\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"4147\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"4147\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"4147\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"4147\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c621d35aa941409b20f5ffb0ebe7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotnine import *\n",
    "import pandas_bokeh\n",
    "pandas_bokeh.output_notebook()\n",
    "\n",
    "path_tabs = create_empty_tabs(paths)\n",
    "\n",
    "for k, tab in path_tabs.items():\n",
    "    with tab:\n",
    "        # reset index dropping old values, then add new index column by resetting again\n",
    "        path = paths[k].copy().reset_index(drop=True).reset_index()\n",
    "        hover_string = '''<span style=\"font-size: 15px;\"><b style=\"color:blue;\">id:</b> $index &nbsp \n",
    "        <b style=\"color:blue;\">(x,y):</b> ($x{0.000}, $y{0.000}) </span>\n",
    "        '''\n",
    "        \n",
    "        path.plot_bokeh.scatter(x='x',y='y',id='index', hovertool_string=hover_string)\n",
    "        display(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# COMPARE SEQUENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Training 17 networks..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 96)\n",
      "input data shape: (96, 256)\n",
      "augmented data shape: (98304, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (97883 of 97883) |##################| Elapsed Time: 0:00:19 Time:  0:00:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 96)\n",
      "input data shape: (96, 256)\n",
      "augmented data shape: (98304, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (97897 of 97897) |##################| Elapsed Time: 0:00:19 Time:  0:00:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 23)\n",
      "input data shape: (23, 256)\n",
      "augmented data shape: (23552, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23133 of 23133) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 23)\n",
      "input data shape: (23, 256)\n",
      "augmented data shape: (23552, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23134 of 23134) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 23)\n",
      "input data shape: (23, 256)\n",
      "augmented data shape: (23552, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23133 of 23133) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24130 of 24130) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24137 of 24137) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24125 of 24125) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24125 of 24125) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24131 of 24131) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24129 of 24129) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24133 of 24133) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24138 of 24138) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24127 of 24127) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24128 of 24128) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24132 of 24132) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shape: (256, 24)\n",
      "input data shape: (24, 256)\n",
      "augmented data shape: (24576, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24130 of 24130) |##################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Calculating linear integrators..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Predicting with each reservoir..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Calculating cosine similitudes..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Done"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create and train reservoir network for each sequence:\n",
    "display(Markdown(f'## Training {len(activations)} networks...'))\n",
    "trained_networks = { k : create_and_train_reservoir(a) for k, a in activations.items() }\n",
    "\n",
    "# create linear integrator for each sequence:\n",
    "display(Markdown(f'## Calculating linear integrators...'))\n",
    "linear_integrators = { k : linear_integrator_states(a.T, 0.95, 1.05) for k, a in activations.items() }\n",
    "\n",
    "# DATA SETS: each sequence must be compared to all sequences in the same data set (we assume the data sets are disjoint)\n",
    "data_sets = {\n",
    "    'synthetic1' : synthetic_set1, \n",
    "    'synthetic2' : synthetic_set2, \n",
    "    'robot' : list(paths_robot.keys()),  \n",
    "    'robot_inverted' : list(paths_robot_inverted.keys())\n",
    "}\n",
    "comparison_data = { k : dset for _, dset in data_sets.items() for k in dset }\n",
    "\n",
    "# predict using each reservoir (only predict sequences in same data set)\n",
    "display(Markdown('### Predicting with each reservoir...'))\n",
    "states = {  k1 :  { k2 : predict_reservoir(n, activations[k2], continuation=False)[1] for k2 in comparison_data[k1]} for k1, n in trained_networks.items()  }\n",
    "\n",
    "# # PRINT DEBUG DATA\n",
    "# print('networks:')\n",
    "# display(trained_networks)\n",
    "# print('state shapes:')\n",
    "# display({ k : s.shape for k, s in reservoir_states_training_data.items() } )\n",
    "\n",
    "# calculate the time series of cosine similitudes betweem input sequences and between reservoir state sequences\n",
    "def all_cos_states(states1, states2):\n",
    "    return [ cos_sim(s1, s2) for (s1, s2) in zip(states1, states2) ]\n",
    "\n",
    "display(Markdown('### Calculating cosine similitudes...'))\n",
    "input_similitudes = { k1 : { k2 : all_cos_states(activations[k1].T, activations[k2].T) for k2 in comparison_data[k1] } for k1 in activations.keys()}\n",
    "state_similitudes = { k1 : { k2 : all_cos_states(states[k1][k1], states[k1][k2]) for k2 in comparison_data[k1] } for k1 in activations.keys() }\n",
    "l_int_similitudes = { k1 : { k2 : all_cos_states(linear_integrators[k1], linear_integrators[k2]) for k2 in comparison_data[k1] } for k1 in activations.keys()}\n",
    "    \n",
    "# DEBUG (toggle comment and indentation): \n",
    "# print cosine similitude at start of sequence\n",
    "# cos_sim_states_0 = { k1 : { k2 : s[0] for k2, s in s_map.items() } for k1, s_map in cos_sim_states.items() }\n",
    "# display(cos_sim_states_0)\n",
    "# plt.plot(cos_sim_states['fss_0']['sfs_0'])\n",
    "# plt.ylim([0,1.1])\n",
    "            \n",
    "display(Markdown('## Done'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PLOT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Number of training sequences: 17"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: path-y-a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5cbb6ad27542cc86c81c0247eba6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), _titles={'0': 'path-y-a', '1': 'path-y-b'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: path-y-b"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffa0382587a476cb92a99efe3021e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), _titles={'0': 'path-y-a', '1': 'path-y-b'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: syn-fss"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16771392f9343d782dbe7207a6c2a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), _titles={'0': 'syn-fss', '1': 'syn-sfs', '2': 'syn-mmm'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: syn-sfs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f0f55c7ad443e4bc587a462c84c9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), _titles={'0': 'syn-fss', '1': 'syn-sfs', '2': 'syn-mmm'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: syn-mmm"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76b73fab5e64765a4dc219bfd784740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), _titles={'0': 'syn-fss', '1': 'syn-sfs', '2': 'syn-mmm'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: fss_0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb64e14fe574d1590b7bbdff0bf5a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0', '1': 'fss_1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: fss_1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3644e8f0a3424c458d92f09d50bca32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0', '1': 'fss_1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: kkk_0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0f5151452647cc9577b1b5e81ae068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0', '1': 'fss_1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: kkk_1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bccbc8ca2c4923ac0f2a9b2bf1dfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0', '1': 'fss_1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: sfs_0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0641bcf72d7f4ae9a8c2b39604c83850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0', '1': 'fss_1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: sfs_1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d536f60d07934f769a0d405fc8950a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0', '1': 'fss_1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: fss_0_inverted"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92abdff501445b8b07e766082ca822e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0_inverted', '1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: fss_1_inverted"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0dc3962e3b493d8bb732342c692bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0_inverted', '1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: kkk_0_inverted"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb5240673284dd7a0d3629aa59e19a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0_inverted', '1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: kkk_1_inverted"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f271bf8c234d3e92ae3faf97de4a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0_inverted', '1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: sfs_0_inverted"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd18e4b5742441ec9e6dae25f4fb9815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0_inverted', '1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Training sequence: sfs_1_inverted"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86d5ac4e10c4658a7b852b0eb935188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'fss_0_inverted', '1'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT ALL SEQUENCES\n",
    "save_folder = 'images/'\n",
    "display(Markdown(f'## Number of training sequences: {len(activations)}'))\n",
    "for k1 in activations.keys():\n",
    "    display(Markdown(f'## Training sequence: {k1}'))\n",
    "    plots = {\n",
    "        k2 :  plot_can_reservoir_distinguish_sequences( activations, states, linear_integrators, input_similitudes, state_similitudes, l_int_similitudes, k1, k2, save_folder)\n",
    "        for k2 in comparison_data[k1]\n",
    "    }\n",
    "    display(create_or_add_to_tab_display(plots))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIXED SELECTIVITY TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Data set: synthetic2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Reservoir sample data shape: (18, 400)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Integrator sample data shape: (18, 256)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Data set: robot"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Reservoir sample data shape: (18, 400)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Integrator sample data shape: (18, 256)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>valye</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>ear</td>\n",
       "      <td>fss</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s1</td>\n",
       "      <td>mid</td>\n",
       "      <td>fss</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s1</td>\n",
       "      <td>late</td>\n",
       "      <td>fss</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>ear</td>\n",
       "      <td>fss</td>\n",
       "      <td>0.2908</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td>mid</td>\n",
       "      <td>fss</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s2</td>\n",
       "      <td>late</td>\n",
       "      <td>fss</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s1</td>\n",
       "      <td>ear</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s1</td>\n",
       "      <td>mid</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s1</td>\n",
       "      <td>late</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s2</td>\n",
       "      <td>ear</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s2</td>\n",
       "      <td>mid</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s2</td>\n",
       "      <td>late</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s1</td>\n",
       "      <td>ear</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s1</td>\n",
       "      <td>mid</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s1</td>\n",
       "      <td>late</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s2</td>\n",
       "      <td>ear</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s2</td>\n",
       "      <td>mid</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s2</td>\n",
       "      <td>late</td>\n",
       "      <td>mmm</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject position sequence   valye speed\n",
       "0       s1      ear      fss  0.3599  fast\n",
       "1       s1      mid      fss  0.3975  slow\n",
       "2       s1     late      fss  0.3278  slow\n",
       "3       s2      ear      fss  0.2908  fast\n",
       "4       s2      mid      fss  0.2844  slow\n",
       "5       s2     late      fss  0.2907  slow\n",
       "6       s1      ear      sfs  0.3724  slow\n",
       "7       s1      mid      sfs  0.3582  fast\n",
       "8       s1     late      sfs  0.2207  slow\n",
       "9       s2      ear      sfs  0.2460  slow\n",
       "10      s2      mid      sfs  0.3044  fast\n",
       "11      s2     late      sfs  0.2779  slow\n",
       "12      s1      ear      mmm  0.3724   med\n",
       "13      s1      mid      mmm  0.3582   med\n",
       "14      s1     late      mmm  0.2207   med\n",
       "15      s2      ear      mmm  0.2460   med\n",
       "16      s2      mid      mmm  0.3044   med\n",
       "17      s2     late      mmm  0.2779   med"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for each data set (synthetic paths and robot paths)\n",
    "sample_states = {}\n",
    "test_data_sets = ['synthetic2', 'robot' ]\n",
    "algorithms = ['Reservoir', 'Interpolator']\n",
    "\n",
    "time_index_map = {\n",
    "    syn_fss : [4, 11, 18, 5, 12, 19],\n",
    "    syn_sfs : [4, 11, 18, 5, 12, 19],\n",
    "    syn_mmm : [4, 11, 18, 5, 12, 19],\n",
    "    'fss_0' : [4, 11, 18],\n",
    "    'fss_1' : [4, 11, 18],\n",
    "    'sfs_0' : [4, 11, 18],\n",
    "    'sfs_1' : [4, 11, 18],\n",
    "    'kkk_0' : [4, 11, 18],\n",
    "    'kkk_1' : [4, 11, 18],\n",
    "}\n",
    "\n",
    "for set_id in test_data_sets:  \n",
    "    groups = data_sets[ set_id ]\n",
    "    s1 = groups[0]\n",
    "    \n",
    "    # get slices of reservoir and integrator states\n",
    "    state_data  = [\n",
    "        np.concatenate([data[s2][time_index_map[s2],:] for s2 in groups])\n",
    "        for data in [states[s1], linear_integrators]\n",
    "    ]\n",
    "    sample_states[set_id] = state_data\n",
    "    \n",
    "    # display debug data\n",
    "    display(Markdown(f'## Data set: {set_id}'))\n",
    "    display(f'Reservoir sample data shape: {state_data[0].shape}',\n",
    "            f'Integrator sample data shape: {state_data[1].shape}')\n",
    "\n",
    "# load template\n",
    "data_template = pd.read_excel(\"test-data-template-3seq.xlsx\")\n",
    "display(Markdown('## Template'))\n",
    "display(data_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecd898a649b430b9f60742aa9396ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output()), _titles={'0': 'synthetic2-Reservoir', '1': 'synthetic2-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG CODE\n",
    "\n",
    "neuron = 50\n",
    "tab_names = [f'{k}-{a}' for k in test_data_sets for a in algorithms ]\n",
    "tabs = create_empty_tabs(tab_names)\n",
    "\n",
    "def fill_template(data):\n",
    "    data_template['valye'] = data[:, neuron]\n",
    "    return data_template.copy()\n",
    "\n",
    "for set_id in test_data_sets:\n",
    "    for d,a in zip([fill_template(s) for s in sample_states[set_id] ], algorithms):\n",
    "        tab_name = f'{set_id}-{a}'\n",
    "    \n",
    "        with tabs[tab_name]:\n",
    "            \n",
    "            display(Markdown(f'# Data'), d)\n",
    "            \n",
    "            anova = pg.anova(dv='valye', between=['position', 'sequence'], data=d, detailed=True)\n",
    "            display(Markdown(f'# Anova'), anova)\n",
    "            \n",
    "            rm_anova = pg.rm_anova(dv='valye', within=['position', 'speed'], subject='subject', data=d, detailed=True)\n",
    "            display(Markdown(f'# Rm_anova'), rm_anova)\n",
    "            \n",
    "            sns.boxplot(hue=\"position\", y=\"valye\", x=\"sequence\", data=d, palette=\"Set3\")\n",
    "            plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed selectivity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e542bdf4384b57b3de889da1af5774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output()), _titles={'0': 'synthetic2-Reservoir', '1': 'synthetic2-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare tabs to display data \n",
    "tab_names = [f'{k}-{a}' for k in test_data_sets for a in algorithms ]\n",
    "tabs = create_empty_tabs(tab_names)\n",
    "\n",
    "# iterate data sets and algorithms\n",
    "for set_id in test_data_sets:\n",
    "    for set_states, a in zip(sample_states[set_id] , algorithms):\n",
    "        tab_name = f'{set_id}-{a}'\n",
    "        with tabs[tab_name]:\n",
    "            \n",
    "            # count cells for which\n",
    "            sign = 0.001\n",
    "            factor ='p-unc'#'p-GG-corr'#\n",
    "            p_count= s_count = ps_count = 0 # count of positions with p-unc < sign\n",
    "            \n",
    "            # iterate each cell\n",
    "            for neuron in range(set_states.shape[1]):\n",
    "                \n",
    "                # compare algorithm states for the different sequences using anova\n",
    "                data_template['valye'] = set_states[:, neuron]\n",
    "                # res = pg.rm_anova(dv='valye', within=['position', 'sequence'], subject='subject', data=data_template, detailed=True)\n",
    "                res = pg.anova(dv='valye', between=['position', 'speed'], data=data_template, detailed=True)\n",
    "                \n",
    "\n",
    "                # count if position (early, mid, late) have different distributions\n",
    "                if res.loc[0,factor] < sign:\n",
    "                    p_count = p_count +1\n",
    "\n",
    "                # count if sequence (fss, sfs, mmm) have different distributions\n",
    "                if res.loc[1,factor] < sign:\n",
    "                    s_count = s_count +1\n",
    "\n",
    "                \n",
    "                if res.loc[0,factor] < sign and res.loc[1,factor] < sign and np.mean(set_states[:,neuron]) > 0:\n",
    "                    print(\"Two way main effect neuron: \", neuron)\n",
    "                    \n",
    "                # count if combined factors have different distribtions\n",
    "                if res.loc[2,factor] < sign:\n",
    "                    ps_count = ps_count +1\n",
    "\n",
    "                    # plot state neuron if it has average positive activation:\n",
    "                    if  np.mean(set_states[:,neuron]) > 0:\n",
    "                        sns.boxplot(hue=\"position\", y=\"valye\", x=\"sequence\", data=data_template, palette=\"Set3\")\n",
    "                        plt.title(f'Interaction neuron: {neuron}')\n",
    "                        plt.show()\n",
    "                        \n",
    "\n",
    "                \n",
    "        \n",
    "            display(f'factor {factor}, sign {sign}')\n",
    "            display(f'position effect    : {p_count}')       \n",
    "            display(f'sequence effect    : {s_count}')       \n",
    "            display(f'pos*seq interaction: {ps_count}')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
